{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e8cb88",
   "metadata": {},
   "source": [
    "# Exploring Dandiset 000617: Allen Institute Openscope - Sequence Learning Project\n",
    "\n",
    "Version: 0.250312.0130\n",
    "\n",
    "**Disclaimer:** This notebook was AI-generated and has not been fully verified. Please be cautious when interpreting the code or results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa5d120",
   "metadata": {},
   "source": [
    "## Overview of the Dandiset\n",
    "\n",
    "This Dandiset, titled \"Allen Institute Openscope - Sequence Learning Project\", focuses on understanding predictive computations in the neocortex using two-photon calcium imaging in mice. The experiments involve presenting sequences of natural movie clips to head-fixed mice and recording neural activity in different cortical areas (V1, LM, AM, PM) and layers (L2/3, L4).\n",
    "\n",
    "The core idea is to investigate how the brain learns to predict upcoming stimuli in a sequence. The experimental design includes:\n",
    "1. A baseline session with random presentation of movie clips (A, B, C) and a grey screen (X).\n",
    "2. Three training sessions where movie clips are presented in a repeating sequence (ABCABC...).\n",
    "3. A final session with random presentation to assess changes due to learning.\n",
    "\n",
    "More information can be found on the DANDI archive: [https://dandiarchive.org/dandiset/000617/0.250312.0130](https://dandiarchive.org/dandiset/000617/0.250312.0130)\n",
    "\n",
    "The Dandiset contains processed neurophysiology data in NWB format, including fluorescence traces, dF/F, detected events, and stimulus information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4bca0",
   "metadata": {},
   "source": [
    "## What this notebook covers\n",
    "\n",
    "This notebook will guide you through:\n",
    "1. Listing required Python packages.\n",
    "2. Loading the Dandiset metadata using the DANDI API.\n",
    "3. Listing some assets (NWB files) within the Dandiset.\n",
    "4. Loading a specific NWB file from the Dandiset.\n",
    "5. Exploring the structure and metadata of the NWB file.\n",
    "6. Visualizing some of the data, such as fluorescence traces and image masks.\n",
    "7. Summarizing findings and suggesting potential future directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe12f49",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "To run this notebook, you will need the following Python packages. This notebook assumes they are already installed.\n",
    "\n",
    "* `dandi` (for interacting with the DANDI Archive)\n",
    "* `pynwb` (for working with NWB files)\n",
    "* `h5py` (as a backend for pynwb to read HDF5 files)\n",
    "* `remfile` (for streaming remote files)\n",
    "* `numpy` (for numerical operations)\n",
    "* `matplotlib` (for plotting)\n",
    "* `pandas` (for data manipulation and display, optional but recommended)\n",
    "* `seaborn` (for enhanced visualizations)\n",
    "\n",
    "You do not need to install these packages if you are running this notebook in an environment where they are already available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e77e3",
   "metadata": {},
   "source": [
    "## Loading the Dandiset using the DANDI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pynwb\n",
    "import h5py\n",
    "import remfile\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn style for plots (except for images)\n",
    "sns.set_theme()\n",
    "\n",
    "# Connect to DANDI archive\n",
    "client = DandiAPIClient()\n",
    "dandiset_id = \"000617\"\n",
    "dandiset_version = \"0.250312.0130\"\n",
    "dandiset = client.get_dandiset(dandiset_id, dandiset_version)\n",
    "\n",
    "# Print basic information about the Dandiset\n",
    "metadata = dandiset.get_raw_metadata()\n",
    "print(f\"Dandiset name: {metadata['name']}\")\n",
    "print(f\"Dandiset URL: {metadata['url']}\")\n",
    "print(f\"Dandiset description: {metadata.get('description', 'No description provided.')}\")\n",
    "\n",
    "# List some assets in the Dandiset\n",
    "assets = dandiset.get_assets()\n",
    "print(\"\\nFirst 5 assets:\")\n",
    "for asset in islice(assets, 5):\n",
    "    print(f\"- {asset.path} (ID: {asset.identifier}, Size: {asset.size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf125d",
   "metadata": {},
   "source": [
    "## Loading an NWB File\n",
    "\n",
    "We will now load one of the NWB files from the Dandiset to explore its contents. We'll select the file `sub-677038/sub-677038_ses-1280089433-acq-1280384858_ophys.nwb`.\n",
    "\n",
    "The URL for this asset is constructed using its asset ID: `27dd7936-b3e7-45af-aca0-dc98b5954d19`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a396bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset details\n",
    "asset_path_to_load = \"sub-677038/sub-677038_ses-1280089433-acq-1280384858_ophys.nwb\"\n",
    "asset_id_to_load = \"27dd7936-b3e7-45af-aca0-dc98b5954d19\" # From the asset listing above\n",
    "nwb_file_url = f\"https://api.dandiarchive.org/api/assets/{asset_id_to_load}/download/\"\n",
    "\n",
    "print(f\"Loading NWB file: {asset_path_to_load}\")\n",
    "print(f\"From URL: {nwb_file_url}\")\n",
    "\n",
    "# Load the NWB file\n",
    "# This uses the exact loading mechanism shown by `tools_cli.py nwb-file-info`\n",
    "remote_file = remfile.File(nwb_file_url)\n",
    "h5_file = h5py.File(remote_file, 'r') # Ensure read-only mode\n",
    "io = pynwb.NWBHDF5IO(file=h5_file, mode='r') # Ensure read-only mode for pynwb\n",
    "nwbfile = io.read()\n",
    "\n",
    "print(\"\\nNWB file loaded successfully.\")\n",
    "print(f\"Identifier: {nwbfile.identifier}\")\n",
    "print(f\"Session description: {nwbfile.session_description}\")\n",
    "print(f\"Session start time: {nwbfile.session_start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236c841",
   "metadata": {},
   "source": [
    "### Explore the NWB file with Neurosift\n",
    "\n",
    "You can explore this NWB file interactively using Neurosift:\n",
    "[https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/27dd7936-b3e7-45af-aca0-dc98b5954d19/download/&dandisetId=000617&dandisetVersion=draft](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/27dd7936-b3e7-45af-aca0-dc98b5954d19/download/&dandisetId=000617&dandisetVersion=draft)\n",
    "\n",
    "*(Note: The link uses `dandisetVersion=draft` as Neurosift typically points to the latest draft version for exploration. The data content should be the same for the specified asset ID).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b24e8c",
   "metadata": {},
   "source": [
    "## Summarizing NWB File Contents\n",
    "\n",
    "Let's look at some of the key data structures within the loaded NWB file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918309f7",
   "metadata": {},
   "source": [
    "### General Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NWB File Identifier: {nwbfile.identifier}\")\n",
    "print(f\"Session Description: {nwbfile.session_description}\")\n",
    "print(f\"Session Start Time: {nwbfile.session_start_time}\")\n",
    "print(f\"Institution: {nwbfile.institution}\")\n",
    "if nwbfile.subject:\n",
    "    print(f\"Subject ID: {nwbfile.subject.subject_id}\")\n",
    "    print(f\"Subject Age: {nwbfile.subject.age}\")\n",
    "    print(f\"Subject Genotype: {nwbfile.subject.genotype}\")\n",
    "    print(f\"Subject Sex: {nwbfile.subject.sex}\")\n",
    "    print(f\"Subject Species: {nwbfile.subject.species}\")\n",
    "if nwbfile.lab_meta_data and 'metadata' in nwbfile.lab_meta_data:\n",
    "    metadata_lab = nwbfile.lab_meta_data['metadata']\n",
    "    print(f\"Ophys Experiment ID: {metadata_lab.ophys_experiment_id}\")\n",
    "    print(f\"Imaging Depth: {metadata_lab.imaging_depth} um\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1feea6",
   "metadata": {},
   "source": [
    "### Acquisition Data\n",
    "\n",
    "The `acquisition` group often contains raw acquired data, like stimulus signals or behavioral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c859eb4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Available data in nwbfile.acquisition:\")\n",
    "for acq_name, acq_data in nwbfile.acquisition.items():\n",
    "    print(f\"- {acq_name}: {type(acq_data)}\")\n",
    "    if hasattr(acq_data, 'description'):\n",
    "        print(f\"  Description: {acq_data.description}\")\n",
    "    if hasattr(acq_data, 'data') and hasattr(acq_data.data, 'shape'):\n",
    "         print(f\"  Data shape: {acq_data.data.shape}\")\n",
    "    if hasattr(acq_data, 'timestamps') and hasattr(acq_data.timestamps, 'shape'):\n",
    "         print(f\"  Timestamps shape: {acq_data.timestamps.shape}\")\n",
    "\n",
    "# Let's plot a small segment of the running wheel signals\n",
    "if \"v_sig\" in nwbfile.acquisition and \"v_in\" in nwbfile.acquisition:\n",
    "    v_sig_ts = nwbfile.acquisition[\"v_sig\"]\n",
    "    v_in_ts = nwbfile.acquisition[\"v_in\"]\n",
    "\n",
    "    # Load a small subset of data to avoid large downloads\n",
    "    num_samples_to_plot = 1000\n",
    "    v_sig_data_subset = v_sig_ts.data[:num_samples_to_plot]\n",
    "    v_sig_timestamps_subset = v_sig_ts.timestamps[:num_samples_to_plot]\n",
    "\n",
    "    v_in_data_subset = v_in_ts.data[:num_samples_to_plot]\n",
    "    # Assuming timestamps are the same for v_in if not explicitly different for this short segment\n",
    "    # v_in_timestamps_subset = v_in_ts.timestamps[:num_samples_to_plot]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(v_sig_timestamps_subset, v_sig_data_subset, label=f'v_sig (Voltage signal) - First {num_samples_to_plot} samples')\n",
    "    plt.plot(v_sig_timestamps_subset, v_in_data_subset, label=f'v_in (Max voltage) - First {num_samples_to_plot} samples', linestyle='--')\n",
    "    plt.xlabel(f\"Time ({v_sig_ts.timestamps_unit})\")\n",
    "    plt.ylabel(f\"Voltage ({v_sig_ts.unit})\")\n",
    "    plt.title(f\"Running Wheel Encoder Signals (First {num_samples_to_plot} samples)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Running wheel signals (v_sig, v_in) not found in nwbfile.acquisition.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173436cc",
   "metadata": {},
   "source": [
    "### Stimulus Templates\n",
    "\n",
    "This file contains templates for the stimuli presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f90a0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\nAvailable stimulus templates in nwbfile.stimulus_template:\")\n",
    "if nwbfile.stimulus_template:\n",
    "    for name, data in nwbfile.stimulus_template.items():\n",
    "        print(f\"- {name}: {type(data)}\")\n",
    "        if hasattr(data, 'data') and hasattr(data.data, 'shape'):\n",
    "            print(f\"  Data shape: {data.data.shape}\")\n",
    "        if hasattr(data, 'format'):\n",
    "            print(f\"  Format: {data.format}\")\n",
    "\n",
    "    # Let's display a frame from one of the movie clips to show how to access it\n",
    "    # We'll take one frame from movie_clip_A\n",
    "    if \"movie_clip_A\" in nwbfile.stimulus_template:\n",
    "        movie_A = nwbfile.stimulus_template[\"movie_clip_A\"]\n",
    "        if hasattr(movie_A, 'data') and len(movie_A.data.shape) == 3: # Assuming (X, Y, Time/Frames)\n",
    "            # Display the first frame\n",
    "            # Data is likely (height, width, frame_index) based on typical video formats\n",
    "            # tools_cli output showed (1280, 720, 120) which might be (height, width, n_frames)\n",
    "            # or (width, height, n_frames) depending on convention. Matplotlib imshow expects (height, width, [channels])\n",
    "            # Let's assume tools_cli output (1280, 720, 120) means (height=1280, width=720, 120 frames)\n",
    "            # but this is unusually tall for a typical movie frame.\n",
    "            # Let's try to infer or just plot. Typical movie aspect is wider than tall.\n",
    "            # The output from tools_cli was: movie_clip_A.data # (Dataset) shape (1280, 720, 120); dtype uint8\n",
    "            # This means 120 frames, each 1280x720. Matplotlib expects (rows, cols_\n",
    "            # If the data is (1280 rows, 720 columns), it's very tall. If (720 rows, 1280 columns) it's more standard.\n",
    "            # Let's assume the shape is (frame_index, height, width) or (height, width, frame_index)\n",
    "            # The nwb-file-info says (1280, 720, 120). Let's assume this is (dim1, dim2, n_frames)\n",
    "            # and that a single frame is (dim1, dim2).\n",
    "            print(f\"Shape of movie_clip_A data: {movie_A.data.shape}\")\n",
    "            if movie_A.data.shape[2] > 0: # Check if there are frames\n",
    "                # Taking the first frame movie_A.data[:, :, 0]\n",
    "                # Be careful with data size.\n",
    "                # Given the shape, it's (1280, 720, 120). A single frame is movie_A.data[:,:,0]\n",
    "                # which is 1280x720. This is a large image. Let's try to plot it.\n",
    "                # No seaborn style for images.\n",
    "                with plt.style.context('default'):\n",
    "                    plt.figure(figsize=(10, 8)) # Adjust as needed\n",
    "                    # Try to plot the first frame.\n",
    "                    # Data is usually H x W. So data[:, :, 0] means a frame of 1280x720.\n",
    "                    try:\n",
    "                        first_frame_A = movie_A.data[:, :, 0]\n",
    "                        plt.imshow(first_frame_A, cmap='gray', aspect='auto') # Aspect auto might be needed for unusual dimensions\n",
    "                        plt.title(\"First Frame of 'movie_clip_A'\")\n",
    "                        plt.xlabel(\"Width (pixels)\")\n",
    "                        plt.ylabel(\"Height (pixels)\")\n",
    "                        plt.colorbar(label=\"Pixel Intensity\")\n",
    "                        plt.show()\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not plot movie frame: {e}. Data shape might be an issue for imshow {movie_A.data.shape}.\")\n",
    "            else:\n",
    "                print(\"'movie_clip_A' data is empty or has no frames.\")\n",
    "        else:\n",
    "            print(\"'movie_clip_A' does not have expected 3D data.\")\n",
    "    else:\n",
    "        print(\"'movie_clip_A' not found in stimulus_template.\")\n",
    "else:\n",
    "    print(\"No stimulus templates found in this NWB file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fbdb81",
   "metadata": {},
   "source": [
    "### Processing Modules (Ophys Data)\n",
    "\n",
    "The `processing` group typically contains derived data, such as fluorescence traces from Regions of Interest (ROIs).\n",
    "\n",
    "This file contains an 'ophys' processing module. Let's explore its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ophys\" in nwbfile.processing:\n",
    "    ophys_module = nwbfile.processing[\"ophys\"]\n",
    "    print(\"Available data interfaces in 'ophys' module:\")\n",
    "    for name, data_interface in ophys_module.data_interfaces.items():\n",
    "        print(f\"- {name}: {type(data_interface)}\")\n",
    "\n",
    "    # Let's focus on 'dff' (Delta F over F) traces\n",
    "    if \"dff\" in ophys_module.data_interfaces:\n",
    "        dff_interface = ophys_module.data_interfaces[\"dff\"]\n",
    "        if hasattr(dff_interface, 'roi_response_series'):\n",
    "            # Typically there's one main RoiResponseSeries, often named 'traces'\n",
    "            if \"traces\" in dff_interface.roi_response_series:\n",
    "                dff_traces = dff_interface.roi_response_series[\"traces\"]\n",
    "                print(f\"\\ndF/F traces ('{dff_traces.name}') found.\")\n",
    "                print(f\"  Description: {dff_traces.description}\")\n",
    "                print(f\"  Data shape (Timepoints x ROIs): {dff_traces.data.shape}\")\n",
    "                print(f\"  Timestamps shape: {dff_traces.timestamps.shape}\")\n",
    "                print(f\"  Unit: {dff_traces.unit}\")\n",
    "\n",
    "                # timestamps_data = dff_traces.timestamps[:] # Load all timestamps\n",
    "                # For plotting, let's take a subset of ROIs and timepoints to keep it manageable\n",
    "                num_rois_to_plot = min(5, dff_traces.data.shape[1])\n",
    "                num_timepoints_to_plot = min(1000, dff_traces.data.shape[0])\n",
    "\n",
    "                # Accessing a subset of data directly: data[start_time:end_time, start_roi:end_roi]\n",
    "                dff_data_subset = dff_traces.data[:num_timepoints_to_plot, :num_rois_to_plot]\n",
    "                timestamps_subset = dff_traces.timestamps[:num_timepoints_to_plot]\n",
    "                \n",
    "                # Get actual ROI IDs if available from the PlaneSegmentation table\n",
    "                roi_ids = []\n",
    "                # Check if we can get specific IDs\n",
    "                can_get_specific_ids = (hasattr(dff_traces, 'rois') and\n",
    "                                        hasattr(dff_traces.rois, 'table') and\n",
    "                                        dff_traces.rois.table is not None and # Ensure table exists\n",
    "                                        'cell_specimen_id' in dff_traces.rois.table.colnames and\n",
    "                                        hasattr(dff_traces.rois.table, '__getitem__') and # make sure table is indexable\n",
    "                                        hasattr(dff_traces.rois, 'data') and # Ensure .data attribute exists for DynamicTableRegion\n",
    "                                        len(dff_traces.rois.data) >= num_rois_to_plot) # Critical check: ensure .rois.data is long enough\n",
    "\n",
    "                if can_get_specific_ids:\n",
    "                    roi_table = dff_traces.rois.table\n",
    "                    # print(f\"Attempting to fetch specific IDs for {num_rois_to_plot} ROIs.\")\n",
    "                    for i in range(num_rois_to_plot):\n",
    "                        try:\n",
    "                            # dff_traces.rois.data[i] gives an index into roi_table for the i-th ROI in dff_traces.data\n",
    "                            roi_table_idx = dff_traces.rois.data[i]\n",
    "                            # Now get the cell_specimen_id from that row in roi_table\n",
    "                            roi_id_val = roi_table['cell_specimen_id'][roi_table_idx]\n",
    "                            if isinstance(roi_id_val, bytes):\n",
    "                                roi_id_val = roi_id_val.decode('utf-8')\n",
    "                            roi_ids.append(str(roi_id_val))\n",
    "                        except Exception as e_single_roi:\n",
    "                            # print(f\"Warning: Could not retrieve specific ID for ROI index {i}, using placeholder. Error: {e_single_roi}\")\n",
    "                            roi_ids.append(f\"ROI {i} (ID err)\") # Append a placeholder to maintain length\n",
    "                    \n",
    "                    if len(roi_ids) == num_rois_to_plot:\n",
    "                         print(f\"Plotting for ROI IDs: {roi_ids}\")\n",
    "                    else:\n",
    "                        # This case indicates a logic flaw or unexpected data structure if reached.\n",
    "                        # print(f\"Warning: roi_ids list length ({len(roi_ids)}) mismatch with num_rois_to_plot ({num_rois_to_plot}). Falling back to generic ROI labels.\")\n",
    "                        roi_ids = [f\"ROI {j}_fallback\" for j in range(num_rois_to_plot)] # Fallback to ensure correct length\n",
    "\n",
    "                else: # Fallback if conditions for specific IDs are not met\n",
    "                    # print(\"Using generic ROI labels as specific IDs could not be retrieved or prerequisites not met.\")\n",
    "                    roi_ids = [f\"ROI {i}_generic\" for i in range(num_rois_to_plot)]\n",
    "\n",
    "\n",
    "                plt.figure(figsize=(15, 7))\n",
    "                for i in range(num_rois_to_plot):\n",
    "                    plt.plot(timestamps_subset, dff_data_subset[:, i], label=f'{roi_ids[i]}')\n",
    "                plt.xlabel(f\"Time ({dff_traces.timestamps_unit})\")\n",
    "                plt.ylabel(\"dF/F\")\n",
    "                plt.title(f\"dF/F Traces for First {num_rois_to_plot} ROIs (First {num_timepoints_to_plot} timepoints)\")\n",
    "                plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                plt.tight_layout(rect=[0,0,0.85,1]) # Adjust layout to make space for legend\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                print(\"No 'traces' found in dff_interface.roi_response_series.\")\n",
    "        else:\n",
    "            print(\"No 'roi_response_series' found in 'dff' interface.\")\n",
    "    else:\n",
    "        print(\"No 'dff' (Delta F over F) interface found in 'ophys' module.\")\n",
    "\n",
    "    # Explore Image Segmentation and Masks\n",
    "    if \"image_segmentation\" in ophys_module.data_interfaces:\n",
    "        img_seg = ophys_module.data_interfaces[\"image_segmentation\"]\n",
    "        if hasattr(img_seg, 'plane_segmentations'):\n",
    "            # PlaneSegmentations holds tables of ROIs, one per imaging plane.\n",
    "            # The example file seems to have one, often named 'cell_specimen_table' or similar\n",
    "            # The NWB file info showed 'cell_specimen_table'\n",
    "            if \"cell_specimen_table\" in img_seg.plane_segmentations:\n",
    "                plane_seg = img_seg.plane_segmentations[\"cell_specimen_table\"]\n",
    "                print(f\"\\nPlane Segmentation table ('{plane_seg.name}') found.\")\n",
    "                print(f\"  Description: {plane_seg.description}\")\n",
    "                print(f\"  Number of ROIs: {len(plane_seg.id)}\") # plane_seg.id gives ElemIdentifiers for ROIs\n",
    "\n",
    "                if 'image_mask' in plane_seg.colnames:\n",
    "                    num_rois_total = len(plane_seg.id)\n",
    "                    print(f\"  Contains 'image_mask' for {num_rois_total} ROIs.\")\n",
    "                    \n",
    "                    # Let's display some ROI masks\n",
    "                    # plane_seg.image_mask is a VectorData containing all masks\n",
    "                    # Each element is a 2D array (height x width)\n",
    "                    # The overall field of view dimensions can be obtained from the imaging plane\n",
    "                    imaging_plane = plane_seg.imaging_plane\n",
    "                    # The imaging_plane.description often contains dimensions, e.g., \"(512, 512) field of view...\"\n",
    "                    # Or from metadata: metadata.field_of_view_width, metadata.field_of_view_height\n",
    "                    # Let's infer from one mask shape if possible, or use known info.\n",
    "                    # The NWB file info showed imaging_plane description: (512, 512) field of view\n",
    "                    # So, actual_fov_height = 512, actual_fov_width = 512\n",
    "                    # However, individual masks in image_mask are often smaller local masks.\n",
    "                    # We would need their x, y offsets from plane_seg columns 'x', 'y' to place them correctly.\n",
    "                    # For simplicity, let's try to plot a few individual masks.\n",
    "                    # And then attempt to reconstruct a composite view if feasible.\n",
    "\n",
    "                    # Let's plot a few individual masks\n",
    "                    num_masks_to_show = min(3, num_rois_total)\n",
    "                    # No seaborn style for images\n",
    "                    with plt.style.context('default'):\n",
    "                        fig, axes = plt.subplots(1, num_masks_to_show, figsize=(5 * num_masks_to_show, 5))\n",
    "                        if num_masks_to_show == 1: # handle single subplot case\n",
    "                            axes = [axes]\n",
    "                        for i in range(num_masks_to_show):\n",
    "                            roi_id_val = plane_seg.id[i] # This is usually just the index 0, 1, 2...\n",
    "                            if 'cell_specimen_id' in plane_seg.colnames:\n",
    "                                roi_csid_val = plane_seg['cell_specimen_id'][i]\n",
    "                                if isinstance(roi_csid_val, bytes):\n",
    "                                     roi_csid_val = roi_csid_val.decode('utf-8')\n",
    "                                plot_title = f\"Image Mask for ROI (ID: {roi_csid_val})\"\n",
    "                            else:\n",
    "                                plot_title = f\"Image Mask for ROI (Index: {roi_id_val})\"\n",
    "                            \n",
    "                            mask_data = plane_seg['image_mask'][i] # This is one mask\n",
    "                            axes[i].imshow(mask_data, cmap='viridis') # Viridis is fine for single masks\n",
    "                            axes[i].set_title(plot_title)\n",
    "                            axes[i].set_xlabel(\"Pixel X\")\n",
    "                            axes[i].set_ylabel(\"Pixel Y\")\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "\n",
    "                    # Create a composite image of all masks superimposed\n",
    "                    # This requires knowing the full FOV dimensions and the x,y offsets of each mask.\n",
    "                    # `plane_seg.imaging_plane.description` provides \" (512, 512) field of view...\"\n",
    "                    # `plane_seg.x` and `plane_seg.y` provide top-left corner.\n",
    "                    fov_height, fov_width = 512, 512 # From NWB file info\n",
    "                    composite_mask_image = np.zeros((fov_height, fov_width), dtype=np.float32)\n",
    "\n",
    "                    print(f\"Attempting to create a composite image of ROI masks on a {fov_height}x{fov_width} canvas.\")\n",
    "                    try:\n",
    "                        all_masks_data = []\n",
    "                        for i in range(num_rois_total):\n",
    "                            mask = plane_seg['image_mask'][i]   # shape (h, w)\n",
    "                            x_offset = int(plane_seg['x'][i])\n",
    "                            y_offset = int(plane_seg['y'][i])\n",
    "                            \n",
    "                            # Add mask to the composite image at its location\n",
    "                            # Ensure mask fits within boundaries\n",
    "                            mask_h, mask_w = mask.shape\n",
    "                            y_end = min(y_offset + mask_h, fov_height)\n",
    "                            x_end = min(x_offset + mask_w, fov_width)\n",
    "                            \n",
    "                            # Slice the mask if it extends beyond FOV (should not happen with correct x,y,h,w)\n",
    "                            mask_slice_h = y_end - y_offset\n",
    "                            mask_slice_w = x_end - x_offset\n",
    "\n",
    "                            if mask_slice_h > 0 and mask_slice_w > 0:\n",
    "                                # Create a temporary full-size canvas for this mask\n",
    "                                temp_mask_canvas = np.zeros((fov_height, fov_width), dtype=mask.dtype)\n",
    "                                temp_mask_canvas[y_offset:y_end, x_offset:x_end] = mask[:mask_slice_h, :mask_slice_w]\n",
    "                                all_masks_data.append(temp_mask_canvas)\n",
    "                        \n",
    "                        if all_masks_data:\n",
    "                            # Stack all full-size mask canvases and take the max projection\n",
    "                            stacked_masks = np.stack(all_masks_data, axis=0)\n",
    "                            composite_mask_image = np.max(stacked_masks, axis=0)\n",
    "\n",
    "                            # No seaborn style for images\n",
    "                            with plt.style.context('default'):\n",
    "                                plt.figure(figsize=(8, 8))\n",
    "                                plt.imshow(composite_mask_image, cmap='viridis', origin='lower') # Use viridis for better perception of values\n",
    "                                plt.title(f\"Composite of {num_rois_total} ROI Masks (Max Projection)\")\n",
    "                                plt.xlabel(\"Pixel X\")\n",
    "                                plt.ylabel(\"Pixel Y\")\n",
    "                                plt.colorbar(label=\"Max Mask Value\")\n",
    "                                plt.show()\n",
    "                        else:\n",
    "                            print(\"No valid masks found to create a composite image.\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not create composite mask image: {e}\")\n",
    "                        print(\"This might be due to issues with mask dimensions, offsets, or data types.\")\n",
    "\n",
    "                else:\n",
    "                    print(\"  'image_mask' column not found in plane segmentation table.\")\n",
    "            else:\n",
    "                print(\"Default 'cell_specimen_table' not found in image_segmentation.plane_segmentations.\")\n",
    "        else:\n",
    "            print(\"No 'plane_segmentations' found in 'image_segmentation' interface.\")\n",
    "    else:\n",
    "        print(\"No 'image_segmentation' interface found in 'ophys' module.\")\n",
    "\n",
    "\n",
    "    # You can similarly explore other data interfaces like 'corrected_fluorescence', 'event_detection', etc.\n",
    "    # For example, to access 'event_detection' data (often inferred spikes):\n",
    "    if 'event_detection' in ophys_module.data_interfaces:\n",
    "        event_det = ophys_module.data_interfaces['event_detection']\n",
    "        print(f\"\\nEvent Detection data ('{event_det.name}') found.\")\n",
    "        # event_det is an OphysEventDetection object, which is an extension of RoiResponseSeries\n",
    "        print(f\"  Data shape (Timepoints x ROIs): {event_det.data.shape}\")\n",
    "        print(f\"  Description: {event_det.description if event_det.description else 'N/A'}\")\n",
    "        # This data often represents event occurrences (e.g., binary or amplitude of detected events)\n",
    "        # Let's plot a raster for a few ROIs if data is not too large\n",
    "        \n",
    "        num_rois_event_plot = min(10, event_det.data.shape[1])\n",
    "        num_timepoints_event_plot = min(2000, event_det.data.shape[0])\n",
    "\n",
    "        event_data_subset = event_det.data[:num_timepoints_event_plot, :num_rois_event_plot]\n",
    "        event_timestamps_subset = event_det.timestamps[:num_timepoints_event_plot]\n",
    "\n",
    "        # Fetch ROI IDs for events\n",
    "        event_roi_ids = []\n",
    "        can_get_specific_event_ids = (hasattr(event_det, 'rois') and\n",
    "                                      hasattr(event_det.rois, 'table') and\n",
    "                                      event_det.rois.table is not None and\n",
    "                                      'cell_specimen_id' in event_det.rois.table.colnames and\n",
    "                                      hasattr(event_det.rois.table, '__getitem__') and\n",
    "                                      hasattr(event_det.rois, 'data') and\n",
    "                                      len(event_det.rois.data) >= num_rois_event_plot)\n",
    "\n",
    "        if can_get_specific_event_ids:\n",
    "            event_roi_table = event_det.rois.table\n",
    "            # print(f\"Attempting to fetch specific IDs for {num_rois_event_plot} event ROIs.\")\n",
    "            for i in range(num_rois_event_plot):\n",
    "                try:\n",
    "                    roi_table_idx = event_det.rois.data[i]\n",
    "                    roi_id_val = event_roi_table['cell_specimen_id'][roi_table_idx]\n",
    "                    if isinstance(roi_id_val, bytes):\n",
    "                        roi_id_val = roi_id_val.decode('utf-8')\n",
    "                    event_roi_ids.append(str(roi_id_val))\n",
    "                except Exception as e_single_event_roi:\n",
    "                    # print(f\"Warning: Could not retrieve specific ID for event ROI index {i}, using placeholder. Error: {e_single_event_roi}\")\n",
    "                    event_roi_ids.append(f\"ROI {i} (ID err)\")\n",
    "            \n",
    "            if len(event_roi_ids) == num_rois_event_plot:\n",
    "                print(f\"Plotting event raster for ROI IDs: {event_roi_ids}\")\n",
    "            else:\n",
    "                # print(f\"Warning: event_roi_ids list length ({len(event_roi_ids)}) mismatch. Falling back.\")\n",
    "                event_roi_ids = [f\"ROI {j}_fallback\" for j in range(num_rois_event_plot)]\n",
    "        else:\n",
    "            # print(\"Using generic ROI labels for events as specific IDs could not be retrieved.\")\n",
    "            event_roi_ids = [f\"ROI {i}_generic\" for i in range(num_rois_event_plot)]\n",
    "        \n",
    "        # For raster, we usually look for non-zero values if data represents event times/amplitudes\n",
    "        # Matplotlib's eventplot is good for this. It expects a list of lists, where each inner list contains event times for one ROI.\n",
    "        event_times_per_roi = []\n",
    "        for i in range(num_rois_event_plot):\n",
    "            # Assuming event_data_subset[:, i] contains values where non-zero indicates an event\n",
    "            # For simplicity, let's consider any positive value as an event occurrence at that timestamp\n",
    "            # This is a simplification; the actual meaning of event_det.data values should be checked.\n",
    "            # Values might be amplitudes, so thresholding might be needed, or they could be binary.\n",
    "            # Let's assume positive values are events for this visualization.\n",
    "            roi_event_indices = np.where(event_data_subset[:, i] > 0)[0] # Get indices of non-zero events\n",
    "            roi_event_times = event_timestamps_subset[roi_event_indices]\n",
    "            event_times_per_roi.append(roi_event_times)\n",
    "\n",
    "        if any(len(times) > 0 for times in event_times_per_roi):\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            # Matplotlib eventplot uses y-positions 0, 1, 2... for the lines.\n",
    "            # Lineoffsets can be used to set the y-value for each ROI.\n",
    "            # Colors can be set per ROI.\n",
    "            plt.eventplot(event_times_per_roi, lineoffsets=np.arange(num_rois_event_plot), linelengths=0.8)\n",
    "            plt.yticks(np.arange(num_rois_event_plot), event_roi_ids[:num_rois_event_plot])\n",
    "            plt.xlabel(f\"Time ({event_det.timestamps_unit})\")\n",
    "            plt.ylabel(\"ROI ID\")\n",
    "            plt.title(f\"Detected Events Raster for First {num_rois_event_plot} ROIs (First {num_timepoints_event_plot} timepoints)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"No events detected (or positive values in data) for the selected subset of ROIs/timepoints for 'event_detection'.\")\n",
    "            \n",
    "else:\n",
    "    print(\"No 'ophys' processing module found in this NWB file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13361a80",
   "metadata": {},
   "source": [
    "### Stimulus Presentation Times\n",
    "\n",
    "Information about when different stimuli were presented is often stored in `nwbfile.intervals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684592b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\nAvailable stimulus presentation tables in nwbfile.intervals:\")\n",
    "if nwbfile.intervals:\n",
    "    for interval_name, time_intervals in nwbfile.intervals.items():\n",
    "        print(f\"- {interval_name}: {type(time_intervals)}\")\n",
    "        if hasattr(time_intervals, 'description'):\n",
    "            print(f\"  Description: {time_intervals.description}\")\n",
    "        # Display a few rows if it's a TimeIntervals table and can be converted to DataFrame\n",
    "        try:\n",
    "            df_interval = time_intervals.to_dataframe()\n",
    "            print(f\"  Columns: {list(df_interval.columns)}\")\n",
    "            print(f\"  First few entries for '{interval_name}':\")\n",
    "            # Use display() for better formatting in Jupyter notebooks if available, else print\n",
    "            try:\n",
    "                from IPython.display import display\n",
    "                display(df_interval.head())\n",
    "            except ImportError:\n",
    "                print(df_interval.head().to_string())\n",
    "        except Exception as e:\n",
    "            print(f\"  Could not convert '{interval_name}' to DataFrame or display head: {e}\")\n",
    "        print(\"-\" * 20)\n",
    "else:\n",
    "    print(\"No interval data found in this NWB file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2cb58",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "* Connect to the DANDI archive and retrieve Dandiset metadata.\n",
    "* List assets within a Dandiset.\n",
    "* Load a specific NWB file using its DANDI asset URL.\n",
    "* Explore the basic structure and metadata of the NWB file, including acquisition data, stimulus templates, o-physiology processed data (dF/F traces, ROI masks, detected events), and stimulus presentation times.\n",
    "* Visualize some of this data, including:\n",
    "    * Running wheel encoder signals.\n",
    "    * A sample frame from a stimulus movie clip.\n",
    "    * dF/F calcium imaging traces for a subset of ROIs.\n",
    "    * Individual ROI masks and a composite image of all masks.\n",
    "    * A raster plot of detected o-physiology events.\n",
    "    * An overview of stimulus presentation tables.\n",
    "\n",
    "The NWB file `sub-677038/sub-677038_ses-1280089433-acq-1280384858_ophys.nwb` contains rich data from a two-photon calcium imaging session. We observed fluorescence traces from 121 ROIs over approximately 4000 seconds (~67 minutes, given an imaging rate around 10Hz and 40019 timestamps). The file also includes spatial masks for these ROIs and detected neurophysiological events. Stimulus presentation times for different movie clips and gray screens are also available, allowing for correlation of neural activity with visual stimuli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b17155",
   "metadata": {},
   "source": [
    "## Possible Future Directions for Analysis\n",
    "\n",
    "Based on the data explored, several analyses could be performed:\n",
    "\n",
    "1.  **Event-Triggered Averages:** Align neural activity (dF/F traces or detected events) to the onset of specific stimuli (e.g., movie_clip_A presentations) to analyze stimulus-evoked responses.\n",
    "2.  **Response Selectivity:** Determine if individual neurons (ROIs) respond preferentially to certain movie clips or during specific parts of the sequence learning experiment.\n",
    "3.  **Correlation Analysis:** Investigate correlations in activity between pairs or populations of neurons. How do these correlations change with learning or different stimuli?\n",
    "4.  **Behavioral Correlation:** If running speed (available in `nwbfile.processing['running']`) is relevant, analyze how neural activity correlates with the animal's movement. The `tools_cli` output showed `running speed` data available.\n",
    "5.  **Population Dynamics:** Use dimensionality reduction techniques (e.g., PCA) on the population activity to explore the neural state space during different experimental conditions.\n",
    "6.  **Cross-Session Comparison:** This Dandiset includes multiple sessions. Comparing neural representations and dynamics across baseline, training, and post-training sessions would be key to understanding the effects of sequence learning. This would involve loading and analyzing other NWB files from the Dandiset.\n",
    "7.  **Predictive Coding Models:** More advanced analyses could involve fitting models that embody predictive coding principles to the observed neural data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a68cc",
   "metadata": {},
   "source": [
    "This notebook provides a starting point for exploring this fascinating Dandiset. Remember to consult the Dandiset documentation and associated publications for more detailed information on the experimental design and data interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f430c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the HDF5 file and the remfile object\n",
    "# It's good practice, though not strictly required by the prompt to omit this.\n",
    "# This ensures resources are released, especially important in scripts or longer sessions.\n",
    "try:\n",
    "    io.close() # This should close the h5_file as well if pynwb manages it.\n",
    "except Exception as e:\n",
    "    print(f\"Error closing pynwb.NWBHDF5IO: {e}\")\n",
    "\n",
    "try:\n",
    "    # h5_file might be closed by io.close() or needs explicit closing\n",
    "    # depending on how pynwb.NWBHDF5IO handles the file object passed to it.\n",
    "    # Let's try to close it if it's not already closed. Check if it has a close method and an id (is open).\n",
    "    if hasattr(h5_file, 'close') and h5_file.id.valid:\n",
    "         h5_file.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error closing h5py.File: {e}\")\n",
    "\n",
    "try:\n",
    "    if hasattr(remote_file, 'close'):\n",
    "         remote_file.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error closing remfile.File: {e}\")\n",
    "\n",
    "print(\"\\nNotebook execution finished. Resources closed.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
