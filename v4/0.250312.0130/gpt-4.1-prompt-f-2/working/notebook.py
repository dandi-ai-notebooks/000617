# %% [markdown]
# # Exploring Dandiset 000617: Allen Institute Openscope - Sequence Learning Project
#
# **WARNING: This notebook was generated by AI and has not been fully verified. Use caution when interpreting code or results.**
#
# ---
#
# ## Overview
# This notebook explores [Dandiset 000617 (version 0.250312.0130)](https://dandiarchive.org/dandiset/000617/0.250312.0130), titled **Allen Institute Openscope - Sequence Learning Project**. The project examines predictive neural coding in mouse neocortex during sequence learning using two-photon calcium imaging. Mice viewed repeated sequences of natural movie clips, and neural/somatic responses were chronicled across sessions using 2-photon imaging and running measurements.

# %% [markdown]
# ## Notebook Aims
# - Summarize the contents and structure of a selected NWB file in this Dandiset.
# - Demonstrate how to load and inspect calcium imaging data, ROI segmentation, stimulus intervals, and behavioral signals.
# - Reproduce key visualizations: ROI mask overlays, sample dF/F calcium traces, and stimulus presentation timing histograms.
# - Highlight how to access, visualize, and contextualize data for further analysis.
#
# **Caution:** Some data are large—subsets are loaded for illustration.

# %% [markdown]
# ## Required Packages
# The Python packages required to run this notebook are:
# - pynwb
# - h5py
# - remfile
# - numpy
# - pandas
# - matplotlib
#
# These are assumed to be installed on your system.

# %%
# Load Dandiset metadata using DANDI API
from itertools import islice
from dandi.dandiapi import DandiAPIClient

client = DandiAPIClient()
dandiset = client.get_dandiset("000617", "0.250312.0130")
metadata = dandiset.get_raw_metadata()
print(f"Dandiset name: {metadata['name']}")
print(f"Dandiset URL: {metadata['url']}")

assets = dandiset.get_assets()
print("\nFirst 5 assets in Dandiset:")
for asset in islice(assets, 5):
    print(f"- {asset.path} (ID: {asset.identifier})")

# %% [markdown]
# ## Working with a Selected NWB File
# 
# We next focus on one NWB file to illustrate data contents and typical analysis. The file used is:
# 
# **sub-677038/sub-677038_ses-1280089433-acq-1280384858_ophys.nwb**
# 
# (Asset ID: `27dd7936-b3e7-45af-aca0-dc98b5954d19`)
#
# URL for this asset:  
# https://api.dandiarchive.org/api/assets/27dd7936-b3e7-45af-aca0-dc98b5954d19/download/
#
# [View this NWB file on Neurosift](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/27dd7936-b3e7-45af-aca0-dc98b5954d19/download/&dandisetId=000617&dandisetVersion=draft)

# %%
# Load the NWB file using PyNWB and remfile (streaming remote file)
import pynwb
import h5py
import remfile
import numpy as np
import pandas as pd

url = "https://api.dandiarchive.org/api/assets/27dd7936-b3e7-45af-aca0-dc98b5954d19/download/"

remote_file = remfile.File(url)
h5_file = h5py.File(remote_file, "r")
io = pynwb.NWBHDF5IO(file=h5_file, load_namespaces=True)
nwb = io.read()

print(f"NWB identifier: {nwb.identifier}")
print(f"Session start: {nwb.session_start_time}")
print(f"Subject ID: {nwb.subject.subject_id}   Species: {nwb.subject.species}")

# %% [markdown]
# ## Summary of File Structure and Metadata
#
# The file contains processed optical physiology (ophys) data, ROI/cell segmentation, stimulus intervals, and running/behavioral measurements. Below is a summary of the ROI/cell segmentation table.
# 
# | Field Name            | Description                                                   |
# |----------------------|---------------------------------------------------------------|
# | `cell_specimen_id`   | Unified cell ID                                               |
# | `height`/`width`     | ROI dimensions (pixels)                                       |
# | `mask_image_plane`   | Identity for non-overlapping ROI mapping                      |
# | `max_correction_*`   | Max motion correction values in pixels (4 directions)         |
# | `valid_roi`          | Boolean, indicates if ROI passes cell classification          |
# | `x`/`y`              | ROI top-left position in image plane (pixels)                 |
# | `image_mask`         | 2D Boolean mask defining ROI shape within the field of view   |
#
# Let's inspect table shape and a sample:

# %%
roi_table = nwb.processing['ophys'].data_interfaces['dff'].roi_response_series['traces'].rois.table
df_info = roi_table.to_dataframe()
print(f"ROI Table: {df_info.shape[0]} ROIs x {df_info.shape[1]} fields")
print("First 5 ROIs:\n", df_info.head())

# %% [markdown]
# ## Visualization: Overlay of ROI Masks on Max Projection Image
#
# This plot overlays all segmented ROI masks on the max projection image of the two-photon field of view.

# %%
import matplotlib.pyplot as plt

roi_masks = np.array(roi_table.image_mask)  # (121, 512, 512), boolean
img_module = nwb.processing['ophys'].data_interfaces["images"]
max_proj = img_module.images["max_projection"].data[:]
if max_proj.shape != (512, 512):
    max_proj = max_proj.T

fig, ax = plt.subplots(figsize=(6,6))
ax.imshow(max_proj, cmap="gray")
mask_heatmap = np.max(roi_masks, axis=0)
ax.imshow(mask_heatmap, cmap="hot", alpha=0.3)
ax.set_title("Overlay of All ROI Masks on Max Projection Image")
ax.axis("off")
plt.tight_layout()
plt.show()

# %% [markdown]
# _The above visualization reveals the spatial layout and coverage of segmentation across the imaging area. ROIs are distributed fairly broadly, with some denser and sparser regions, and minimal overlap._

# %% [markdown]
# ## dF/F Calcium Traces for Sample ROIs
#
# Here are example calcium activity traces (dF/F) for six ROIs, chosen in order from the segmentation table. This highlights temporal diversity in neural responses.

# %%
dff = nwb.processing['ophys'].data_interfaces['dff'].roi_response_series['traces']
timestamps = dff.timestamps[:]
data = dff.data[:, :6]  # (frames, 6)
roi_ids = list(dff.rois.table.id[:6])

fig, axs = plt.subplots(6, 1, figsize=(10, 10), sharex=True)
for i in range(6):
    axs[i].plot(timestamps, data[:, i], lw=0.4)
    axs[i].set_ylabel(f'ROI {roi_ids[i]}')
axs[0].set_title('Example dF/F Calcium Traces for 6 ROIs')
axs[-1].set_xlabel('Time (s)')
plt.tight_layout()
plt.show()

# %% [markdown]
# _Note the pronounced diversity in trace shape and event frequency among cells—reflecting both biological and experimental heterogeneity._

# %% [markdown]
# ## Blocked Stimulus Presentations: "Movie Clip A"
#
# Let's check when the first 200 presentations of "movie_clip_A" stimulus occur. A histogram of the start times makes the temporal structure apparent.

# %%
movie_A_intv = nwb.intervals["movie_clip_A_presentations"].to_dataframe()
start_times = movie_A_intv["start_time"].values[:200]

plt.figure(figsize=(8,4))
plt.hist(start_times, bins=30, color="blue", alpha=0.7)
plt.xlabel("Time (s)")
plt.ylabel("Presentation count")
plt.title("Histogram of Start Times for First 200\nMovie Clip A Presentations")
plt.tight_layout()
plt.show()

# %% [markdown]
# _The bimodal structure above reveals that presentations are grouped into repeated blocks or sessions rather than being uniformly scattered, highlighting the experiment's structure._

# %% [markdown]
# ## Summary and Future Directions
#
# This notebook demonstrated access, structural inspection, and visualization for Dandiset 000617 (Sequence Learning Project). Key points:
# - The dataset features rich two-photon imaging data, processed ROI/cell segmentation, event and dF/F traces, and behavioral recordings.
# - Several kinds of analysis are possible including population summary statistics, stimulus-triggered averaging, and decoding approaches.
#
# **Possible next steps:**
# - Link behavioral running speed to neural responses.
# - Explore stimulus-locked averaging and single-cell selectivity.
# - Compare different experiment days or stimulus identities.
#
# Please refer to the raw and processed data for more sophisticated analyses and for temporal alignment with stimulus behavior.
#
# **Remember:** This notebook is AI-generated; always critically validate code and outputs before basing further scientific conclusions on them.